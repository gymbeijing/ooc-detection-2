{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281c8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, cast\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from functools import wraps\n",
    "from multiprocessing.process import BaseProcess\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f058c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\ttrain_image_ids.jsonl  train_text_ids.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /import/network-temp/yimengg/data/twitter-comms/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681e144",
   "metadata": {},
   "source": [
    "# Prepare tweet (image) ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e884a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"../data/val.csv\")\n",
    "\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1304ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>falsified</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1409530436481687559</td>\n",
       "      <td>1409530436481687559</td>\n",
       "      <td>False</td>\n",
       "      <td>climate_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1409530436481687559</td>\n",
       "      <td>1409467086443794439</td>\n",
       "      <td>True</td>\n",
       "      <td>climate_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1420581355176480770</td>\n",
       "      <td>1420581355176480770</td>\n",
       "      <td>False</td>\n",
       "      <td>climate_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1420581355176480770</td>\n",
       "      <td>1410982452609302531</td>\n",
       "      <td>True</td>\n",
       "      <td>climate_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1415615378546466819</td>\n",
       "      <td>1415615378546466819</td>\n",
       "      <td>False</td>\n",
       "      <td>climate_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468587</th>\n",
       "      <td>2468587</td>\n",
       "      <td>1246868705755181056</td>\n",
       "      <td>1275658124150689792</td>\n",
       "      <td>True</td>\n",
       "      <td>military_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468588</th>\n",
       "      <td>2468588</td>\n",
       "      <td>1389988511084908546</td>\n",
       "      <td>1389988511084908546</td>\n",
       "      <td>False</td>\n",
       "      <td>military_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468589</th>\n",
       "      <td>2468589</td>\n",
       "      <td>1389988511084908546</td>\n",
       "      <td>937309139788759040</td>\n",
       "      <td>True</td>\n",
       "      <td>military_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468590</th>\n",
       "      <td>2468590</td>\n",
       "      <td>930708308033458176</td>\n",
       "      <td>930708308033458176</td>\n",
       "      <td>False</td>\n",
       "      <td>military_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468591</th>\n",
       "      <td>2468591</td>\n",
       "      <td>930708308033458176</td>\n",
       "      <td>773856326279696388</td>\n",
       "      <td>True</td>\n",
       "      <td>military_random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2468592 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                   id             image_id  falsified  \\\n",
       "0                 0  1409530436481687559  1409530436481687559      False   \n",
       "1                 1  1409530436481687559  1409467086443794439       True   \n",
       "2                 2  1420581355176480770  1420581355176480770      False   \n",
       "3                 3  1420581355176480770  1410982452609302531       True   \n",
       "4                 4  1415615378546466819  1415615378546466819      False   \n",
       "...             ...                  ...                  ...        ...   \n",
       "2468587     2468587  1246868705755181056  1275658124150689792       True   \n",
       "2468588     2468588  1389988511084908546  1389988511084908546      False   \n",
       "2468589     2468589  1389988511084908546   937309139788759040       True   \n",
       "2468590     2468590   930708308033458176   930708308033458176      False   \n",
       "2468591     2468591   930708308033458176   773856326279696388       True   \n",
       "\n",
       "                   topic  \n",
       "0           climate_hard  \n",
       "1           climate_hard  \n",
       "2           climate_hard  \n",
       "3           climate_hard  \n",
       "4           climate_hard  \n",
       "...                  ...  \n",
       "2468587  military_random  \n",
       "2468588  military_random  \n",
       "2468589  military_random  \n",
       "2468590  military_random  \n",
       "2468591  military_random  \n",
       "\n",
       "[2468592 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e79159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet ids of the images in each entry\n",
    "id_list = val_df[\"image_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09e6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet ids of the captions (text) in each entry\n",
    "txt_id_list = val_df[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b6a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = train_df[\"image_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbfa6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(txt_id_list)\n",
    "\n",
    "with open(\"val_tweet_text_ids.txt\", 'w') as fr:\n",
    "    for idx, tweet_id in enumerate(txt_id_list):\n",
    "        fr.write(str(tweet_id))\n",
    "        if idx != length - 1:\n",
    "            fr.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86692464",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(id_list)\n",
    "\n",
    "with open(\"train_image_ids.txt\", 'w') as fr:\n",
    "    for idx, tweet_id in enumerate(id_list):\n",
    "        fr.write(str(tweet_id))\n",
    "        if idx != length - 1:\n",
    "            fr.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea13a86",
   "metadata": {},
   "source": [
    "# Load json lines into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bea013",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/val_tweet_ids.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87b8740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4727a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    tweets.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a600306",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664813b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23260\n"
     ]
    }
   ],
   "source": [
    "with open('../data/val_tweet_image_ids.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "print(len(json_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef798c5d",
   "metadata": {},
   "source": [
    "# Test download_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ac9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    level=os.environ.get(\"LOGLEVEL\", \"INFO\"),\n",
    "    format=\"[%(asctime)s]:[%(processName)-11s]\" + \"[%(levelname)-s]:[%(name)s] %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c198bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastTime:\n",
    "    \"\"\"\n",
    "    Credit: Copied and modified this: https://gist.github.com/gregburek/1441055\n",
    "    >>> import rate_limited as rt\n",
    "    >>> a = rt.LastTime()\n",
    "    >>> a.add_cnt()\n",
    "    >>> a.get_cnt()\n",
    "    1\n",
    "    >>> a.add_cnt()\n",
    "    >>> a.get_cnt()\n",
    "    2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"LT\"):\n",
    "        # Init variables to None\n",
    "        self.name = name\n",
    "        self.ratelock = None\n",
    "        self.cnt = None\n",
    "        self.last_time_called = None\n",
    "\n",
    "        # Instantiate control variables\n",
    "        self.ratelock = multiprocessing.Lock()\n",
    "        self.cnt = multiprocessing.Value(\"i\", 0)\n",
    "        self.last_time_called = multiprocessing.Value(\"d\", 0.0)\n",
    "\n",
    "        logging.debug(\"\\t__init__: name=[{!s}]\".format(self.name))\n",
    "\n",
    "    def acquire(self):\n",
    "        self.ratelock.acquire()\n",
    "\n",
    "    def release(self):\n",
    "        self.ratelock.release()\n",
    "\n",
    "    def set_last_time_called(self):\n",
    "        self.last_time_called.value = time.time()\n",
    "        # self.debug('set_last_time_called')\n",
    "\n",
    "    def get_last_time_called(self):\n",
    "        return self.last_time_called.value\n",
    "\n",
    "    def add_cnt(self):\n",
    "        self.cnt.value += 1\n",
    "\n",
    "    def get_cnt(self):\n",
    "        return self.cnt.value\n",
    "\n",
    "    def debug(self, debugname=\"LT\"):\n",
    "        now = time.time()\n",
    "        logging.debug(\n",
    "            \"___Rate name:[{!s}] \"\n",
    "            \"debug=[{!s}] \"\n",
    "            \"\\n\\t        cnt:[{!s}] \"\n",
    "            \"\\n\\tlast_called:{!s} \"\n",
    "            \"\\n\\t  timenow():{!s} \".format(\n",
    "                self.name,\n",
    "                debugname,\n",
    "                self.cnt.value,\n",
    "                time.strftime(\n",
    "                    \"%T.{}\".format(\n",
    "                        str(self.last_time_called.value - int(self.last_time_called.value)).split(\n",
    "                            \".\"\n",
    "                        )[1][:3]\n",
    "                    ),\n",
    "                    time.localtime(self.last_time_called.value),\n",
    "                ),\n",
    "                time.strftime(\n",
    "                    \"%T.{}\".format(str(now - int(now)).split(\".\")[1][:3]), time.localtime(now)\n",
    "                ),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec6233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(json_path: Path) -> pd.DataFrame:\n",
    "    assert json_path.exists(), str(json_path) \n",
    "    df = pd.read_json(\n",
    "        json_path,\n",
    "        lines=True,\n",
    "        precise_float=True,\n",
    "        dtype={\"id\": int, \"id_str\":int},  # specify the datatype of id_str (int), otherwise will lose precision\n",
    "    )\n",
    "    # Note: id_str matches the tweet_id's that are passed into hydrator:\n",
    "    df[\"tweet_id\"] = df.id_str.astype(int)\n",
    "#     df[\"tweet_id\"] = df.id_str\n",
    "    df = df.drop_duplicates(\"tweet_id\")   # each tweet id tends to appear ~twice\n",
    "    df.set_index(\n",
    "        \"tweet_id\",\n",
    "        drop=False,   # used to be False\n",
    "        inplace=True,\n",
    "        verify_integrity=True,\n",
    "    )\n",
    "    df[\"country\"] = df.geo.apply(\n",
    "        lambda x: x[\"country\"] if isinstance(x, dict) and \"country\" in x else None\n",
    "    )\n",
    "    return cast(pd.DataFrame, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940e1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_json_normalize(\n",
    "    row, parent_col_name: str, target_col_name: str, child_properties: list = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Prepares a column of a dataframe (`target_col_name`) to be run through\n",
    "    `json_normalize()`. To achieve this it takes a row of a dataframe containing tweet\n",
    "    data, and:\n",
    "    1. Adds the `parent_col_name: row[parent_col_name]` as a key-value pair to the dict\n",
    "        object contained in `row[target_col_name]`. This helps link the rows of the\n",
    "        original DataFrame to those of the DataFrame that is output when the target\n",
    "        column is run thru `json_normalize()`.\n",
    "    2. Adds a `\"media\": []` key-value pair if no media key is in the target dict.\n",
    "    3. If the target dict is null, a new one is created.\n",
    "    \"\"\"\n",
    "    target_dict = row[target_col_name]\n",
    "    if not isinstance(target_dict, dict):\n",
    "        target_dict = {}\n",
    "    if parent_col_name not in target_dict:\n",
    "        target_dict[parent_col_name] = row[parent_col_name]\n",
    "    if child_properties:\n",
    "        for prop_name, prop_type in child_properties:\n",
    "            if prop_name not in target_dict:\n",
    "                target_dict[prop_name] = prop_type()\n",
    "    return target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9060028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_urls(json_path: Path, media_type: str = \"photo\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame of media info from the give json file. The input file should be a twitter\n",
    "    json file that came from the Twitter v2 Search API.\n",
    "    Example output:\n",
    "        >       height              id_str   type                                              url  width  duration_ms preview_image_url  public_metrics.view_count alt_text             tweet_id             filename\n",
    "        > 0       1920  3_1427530554480619521  photo  https://pbs.twimg.com/media/E8-bedXVcAEqkXA.jpg   1080          NaN               NaN                        NaN      NaN  1427531793771622400    xx/<filename>.jpg\n",
    "        > 1        409  3_1427531788591771661  photo  https://pbs.twimg.com/media/E8-cmSyXMA0ETDr.jpg    615          NaN               NaN                        NaN      NaN  1427531789392883727    xx/<filename>.jpg\n",
    "        > 2       1000  3_1427531783868878850  photo  https://pbs.twimg.com/media/E8-cmBMVkAIcD4a.jpg   1000          NaN               NaN                        NaN      NaN  1427531786746163202    xx/<filename>.jpg\n",
    "        > 3        546  3_1427531482029903875  photo  https://pbs.twimg.com/media/E8-cUcwUUAMRefa.jpg    728          NaN               NaN                        NaN      NaN  1427531786477740034    xx/<filename>.jpg\n",
    "        > 4        375  3_1427526863543578632  photo  https://pbs.twimg.com/media/E8-YHnjXsAgRpIu.jpg    500          NaN               NaN                        NaN      NaN  1427531785458659334    xx/<filename>.jpg\n",
    "        > ...      ...                    ...    ...                                              ...    ...          ...               ...                        ...      ...                  ...                  ...\n",
    "    \"\"\"\n",
    "    df = load_tweets(json_path)\n",
    "    if \"attachments\" in df.columns:\n",
    "        df[\"attachments\"] = df.apply(\n",
    "            lambda row: pre_json_normalize(row, \"tweet_id\", \"attachments\", [(\"media\", list)]), axis=1\n",
    "        )\n",
    "        df_media = pd.json_normalize(df.attachments, record_path=\"media\", meta=[\"tweet_id\"])\n",
    "    else:\n",
    "        df[\"entities\"] = df.apply(\n",
    "            lambda row: pre_json_normalize(row, \"tweet_id\", \"entities\", [(\"media\", list)]), axis=1\n",
    "        )\n",
    "        df_media = pd.json_normalize(df.entities, record_path=\"media\", meta=[\"tweet_id\"])\n",
    "    df_media = df_media[(df_media.type == media_type) & ~df_media.media_url.isna()]   # might filtered out some rows\n",
    "    df_media.reset_index(inplace=True)\n",
    "    df_media.index.name = \"id\"\n",
    "\n",
    "    def _get_filename(row):\n",
    "        extension = Path(row[\"media_url\"]).suffix if row[\"media_url\"] and not pd.isna(row[\"media_url\"]) else None\n",
    "        filename = f\"{row['id_str'][-2:]}/{row['tweet_id']}-{row['id_str']}{extension}\"\n",
    "        return filename\n",
    "\n",
    "    df_media[\"filename\"] = df_media.apply(lambda row: _get_filename(row), axis=1)\n",
    "    df.index.names = ['index']\n",
    "#     df = df[['tweet_id', 'full_text']]\n",
    "#     df_media = df_media.merge(df, on='tweet_id')\n",
    "    logger.info(f\"Found {len(df_media)} media urls of type: '{media_type}'\")\n",
    "#     print(df_media)\n",
    "    return cast(pd.DataFrame, df_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60af95af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_limited(max_per_second):\n",
    "    \"\"\"\n",
    "    Decorator to rate limit a python function.\n",
    "    Example, limits to 10 requests per second, and works w/ multiprocessing as well:\n",
    "        > @rate_limited(10)\n",
    "        > def download_img(media_url):\n",
    "        > ...\n",
    "    Credit: Copied and modified this: https://gist.github.com/gregburek/1441055\n",
    "    \"\"\"\n",
    "    min_interval = 1.0 / max_per_second\n",
    "    LT = LastTime(\"rate_limited\")\n",
    "\n",
    "    def decorate(func):\n",
    "        LT.acquire()\n",
    "        if LT.get_last_time_called() == 0:\n",
    "            LT.set_last_time_called()\n",
    "        LT.debug(\"DECORATE\")\n",
    "        LT.release()\n",
    "\n",
    "        @wraps(func)\n",
    "        def rate_limited_function(*args, **kwargs):\n",
    "\n",
    "            logging.debug(\n",
    "                \"___Rate_limited f():[{!s}]: \"\n",
    "                \"Max_per_Second:[{!s}]\".format(func.__name__, max_per_second)\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                LT.acquire()\n",
    "                LT.add_cnt()\n",
    "                xfrom = time.time()\n",
    "\n",
    "                elapsed = xfrom - LT.get_last_time_called()\n",
    "                left_to_wait = min_interval - elapsed\n",
    "                logging.debug(\n",
    "                    \"___Rate f():[{!s}] \"\n",
    "                    \"cnt:[{!s}] \"\n",
    "                    \"\\n\\tlast_called:{!s} \"\n",
    "                    \"\\n\\t time now():{!s} \"\n",
    "                    \"elapsed:{:6.2f} \"\n",
    "                    \"min:{!s} \"\n",
    "                    \"to_wait:{:6.2f}\".format(\n",
    "                        func.__name__,\n",
    "                        LT.get_cnt(),\n",
    "                        time.strftime(\"%T\", time.localtime(LT.get_last_time_called())),\n",
    "                        time.strftime(\"%T\", time.localtime(xfrom)),\n",
    "                        elapsed,\n",
    "                        min_interval,\n",
    "                        left_to_wait,\n",
    "                    )\n",
    "                )\n",
    "                if left_to_wait > 0:\n",
    "                    time.sleep(left_to_wait)\n",
    "\n",
    "                ret = func(*args, **kwargs)\n",
    "\n",
    "                LT.debug(\"OVER\")\n",
    "                LT.set_last_time_called()\n",
    "                LT.debug(\"NEXT\")\n",
    "\n",
    "            except Exception as ex:\n",
    "                sys.stderr.write(\n",
    "                    \"+++000 \" \"Exception on rate_limited_function: [{!s}]\\n\".format(ex)\n",
    "                )\n",
    "                sys.stderr.flush()\n",
    "                raise\n",
    "            finally:\n",
    "                LT.release()\n",
    "            return ret\n",
    "\n",
    "        return rate_limited_function\n",
    "\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497c07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rate_limited(30)\n",
    "def save_image(idx, img_row, images_dir: Path, size=\"large\"):\n",
    "    \"\"\"\n",
    "    Download and save image to path.\n",
    "    Args:\n",
    "        image: The url of the image.\n",
    "        path: The directory where the image will be saved.\n",
    "        filename:\n",
    "        size: Which size of images to download.\n",
    "    \"\"\"\n",
    "    if img_row[\"media_url\"]:\n",
    "        save_dest: Path = images_dir / img_row[\"filename\"]\n",
    "        save_dest.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        if not save_dest.exists():\n",
    "            # logger.info(f\"Saving image: {save_dest.name}\")\n",
    "            r = requests.get(img_row[\"media_url\"] + \":\" + size, stream=True)\n",
    "            if r.status_code == 200:\n",
    "                with open(save_dest, \"wb\") as f:\n",
    "                    r.raw.decode_content = True\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "            elif r.status_code in [403, 404]:\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Error on {idx}, tweet_id:{img_row['tweet_id']}, url:{img_row['media_url']}\")\n",
    "                print(r.headers)\n",
    "                print(r.status_code, \", \", r.reason)\n",
    "                print(r.text)\n",
    "            if r.status_code in [429]:\n",
    "                sleep_seconds = 15 * 60\n",
    "                logger.error(f\"Rate limit hit... Will retry in {sleep_seconds} seconds...\")\n",
    "                time.sleep(sleep_seconds)\n",
    "        else:\n",
    "            # print(f\"Skipping {save_dest}: already downloaded\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e2eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_images(df_media: pd.DataFrame, images_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Single process, just download one images at a time.\n",
    "    \"\"\"\n",
    "    for idx, row in df_media.iterrows():\n",
    "        save_image(idx, row, images_dir, size=\"orig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598dcbfa",
   "metadata": {},
   "source": [
    "# Prepare completed val set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58af0c0",
   "metadata": {},
   "source": [
    "## Step 1: load (text)tweet json lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9407368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load_tweets()\n",
    "df = load_tweets(Path('../data/val_tweet_text_ids.jsonl'))\n",
    "\n",
    "df   # 5,884 (23,261) lines after (before) dropping duplicates, no matter having .astype(int) or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f717eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the <tweet id> and the <text>\n",
    "df = df[['id_str', 'full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49c5a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1426453420483899393</th>\n",
       "      <td>1426453420483899393</td>\n",
       "      <td>@Miese_m My niece by marriage from Uganda is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419908270291144710</th>\n",
       "      <td>1419908270291144710</td>\n",
       "      <td>COP26: Torrential rain and floods 'on our own ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413479002917019653</th>\n",
       "      <td>1413479002917019653</td>\n",
       "      <td>This is what is happening to Bugoma Forest in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398623654125133825</th>\n",
       "      <td>1398623654125133825</td>\n",
       "      <td>@KaibaSetio What has your BLM ever done for an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397902224135700481</th>\n",
       "      <td>1397902224135700481</td>\n",
       "      <td>Today the groundwork begins to replace our agi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id_str  \\\n",
       "tweet_id                                   \n",
       "1426453420483899393  1426453420483899393   \n",
       "1419908270291144710  1419908270291144710   \n",
       "1413479002917019653  1413479002917019653   \n",
       "1398623654125133825  1398623654125133825   \n",
       "1397902224135700481  1397902224135700481   \n",
       "\n",
       "                                                             full_text  \n",
       "tweet_id                                                                \n",
       "1426453420483899393  @Miese_m My niece by marriage from Uganda is a...  \n",
       "1419908270291144710  COP26: Torrential rain and floods 'on our own ...  \n",
       "1413479002917019653  This is what is happening to Bugoma Forest in ...  \n",
       "1398623654125133825  @KaibaSetio What has your BLM ever done for an...  \n",
       "1397902224135700481  Today the groundwork begins to replace our agi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf485a34",
   "metadata": {},
   "source": [
    "## Step 2: load val.csv and merge with df to append text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4772af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../data/val.csv', \n",
    "                     index_col=0,\n",
    "                     dtype={\"id\": int, \"id_str\":int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c10be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.merge(df, left_on='id', right_on='id_str')\n",
    "\n",
    "# df_val\n",
    "\n",
    "df_val = df_val[['id', 'full_text', 'image_id', 'falsified', 'topic']]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv('../data/val_full_text_completed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e8aed",
   "metadata": {},
   "source": [
    "## Step 3: load (image)tweet json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_photo_urls()\n",
    "df_media = get_photo_urls(Path('../data/val_tweet_image_ids.jsonl'))\n",
    "df_media   # 5859 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e0b3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = df_media.rename({'id': 'media_id', 'id_str': 'media_id_str'}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a86c8d",
   "metadata": {},
   "source": [
    "## Step 4: load val.csv from step 2 and merge with df_media to append image filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../data/val_full_text_completed.csv', \n",
    "                     index_col=0,\n",
    "                     dtype={\"id\": int, \"id_str\":int})\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79b1cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.merge(df_media, left_on='image_id', right_on='tweet_id')\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2db1f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val[['id', 'full_text', 'image_id', 'filename', 'falsified', 'topic']]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecc5fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv('../data/val_completed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b486c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786abdbe",
   "metadata": {},
   "source": [
    "# Prepare completed train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ea0fb",
   "metadata": {},
   "source": [
    "## Step 1: load (text)tweet json lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f3db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_tweets(Path('/import/network-temp/yimengg/data/twitter-comms/train/train_text_ids.jsonl'))\n",
    "\n",
    "# Only keep the <tweet id> and the <text>\n",
    "df = df[['id_str', 'full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854a9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_str        int64\n",
       "full_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d9af6",
   "metadata": {},
   "source": [
    "## Step 2: load train.csv and merge with df to append text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4bf0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv', \n",
    "                     index_col=0,\n",
    "                     dtype={\"id\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc5a9797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            int64\n",
       "image_id      int64\n",
       "falsified      bool\n",
       "topic        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84ca291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train['id'].isna().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dcb07ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            int64\n",
       "full_text    object\n",
       "image_id      int64\n",
       "falsified      bool\n",
       "topic        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.merge(df, left_on='id', right_on='id_str')\n",
    "\n",
    "# df_val\n",
    "\n",
    "df_train = df_train[['id', 'full_text', 'image_id', 'falsified', 'topic']]\n",
    "\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ede113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['full_text'] = df_train['full_text'].apply(lambda text: text.replace('\\r', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbdfbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_read = pd.read_csv('/import/network-temp/yimengg/data/twitter-comms/train/train_full_text_completed.csv', \n",
    "#                      index_col=0,\n",
    "#                      dtype={\"id\": 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "651fa485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = pd.isnull(df_train_read).any(1).to_numpy().nonzero()\n",
    "\n",
    "# inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c2e785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/import/network-temp/yimengg/data/twitter-comms/train/train_full_text_completed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7a2af",
   "metadata": {},
   "source": [
    "## Step 3: load (image)tweet json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_photo_urls()\n",
    "df_media = get_photo_urls(Path('/import/network-temp/yimengg/data/twitter-comms/train/train_image_ids.jsonl'))\n",
    "df_media   # 5859 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = df_media.rename({'id': 'media_id', 'id_str': 'media_id_str'}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de851266",
   "metadata": {},
   "source": [
    "## Step 4: load train.csv from step 2 and merge with df_media to append image filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/import/network-temp/yimengg/data/twitter-comms/train/train_full_text_completed.csv', \n",
    "                     index_col=0,\n",
    "                     dtype={\"id\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_media, left_on='image_id', right_on='tweet_id')\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['id', 'full_text', 'image_id', 'filename', 'falsified', 'topic']]\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59482f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/train_completed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "images_dir: Path = data_dir / \"images\"\n",
    "images_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367fdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_images(df_media.head(2), images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce16fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
